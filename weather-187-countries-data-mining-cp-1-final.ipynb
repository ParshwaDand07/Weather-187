{"cells":[{"cell_type":"markdown","metadata":{},"source":["# **Team - 29 Data Wizards**\n","# The Weather of 187 Countries in 2020 Dataset\n","#### In this dataset, data is collected from different weather stations across all 187 countries. It contains around 23 different features such as Snow, Snow Depth, Average Temp, Max Temp, Min Temp, Date, Country, Station, etc. and out of which many features contains more than 90% of the values as Null."]},{"cell_type":"code","execution_count":1,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","from sklearn import preprocessing\n","import matplotlib.pyplot as plt\n","from sklearn.model_selection import GridSearchCV \n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import mean_squared_error\n","from sklearn.linear_model import Ridge\n","from sklearn.linear_model import SGDRegressor\n","from sklearn.linear_model import ElasticNet\n","from sklearn.metrics import mean_absolute_error\n","from sklearn.svm import SVR\n","from sklearn.linear_model import LinearRegression\n","from sklearn.preprocessing import PolynomialFeatures\n","from sklearn.pipeline import make_pipeline\n","from sklearn.linear_model import Lasso\n","import calendar\n","import warnings \n","warnings.filterwarnings('ignore')"]},{"cell_type":"markdown","metadata":{},"source":["## 1. Loading Weather Data\n","\n","In this code snippet, weather data is loaded from a CSV file named \"the weather of 187 countries in 2020.csv.\" This dataset contains information about weather conditions across 187 countries for the year 2020. It is in this GitHub Repo itself. It can also be obtained from [Kaggle](https://www.kaggle.com/datasets/amirhoseinsedaghati/the-weather-of-187-countries-in-2020?select=the+weather+of+187+countries+in+2020.csv)."]},{"cell_type":"code","execution_count":4,"metadata":{"trusted":true},"outputs":[],"source":["weather_data = pd.read_csv('the weather of 187 countries in 2020.csv')"]},{"cell_type":"markdown","metadata":{},"source":["## 2. Exploratory Data Analysis (EDA)"]},{"cell_type":"markdown","metadata":{},"source":["#### 1. Missing Data Percentage\n","This code calculates the percentage of missing values in each column of the `weather_data` DataFrame. It computes the sum of missing values for each column using `isnull().sum()`, and then divides it by the total number of rows (`weather_data.shape[0]`) to obtain the missing data percentage.\n","\n","Understanding the extent of missing data is crucial for data preprocessing and quality assessment in data analysis tasks."]},{"cell_type":"code","execution_count":5,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["STATION            0.000000\n","Country/Region     0.000000\n","DATE               0.000000\n","Year               0.000000\n","Month              0.000000\n","Day                0.000000\n","PRCP               0.295747\n","SNWD               0.795578\n","TAVG               0.225397\n","TMAX               0.364050\n","TMIN               0.337800\n","SNOW               0.900826\n","LATITUDE           0.902432\n","LONGITUDE          0.902432\n","ELEVATION          0.902432\n","PRCP_ATTRIBUTES    0.994271\n","TAVG_ATTRIBUTES    0.996328\n","TMAX_ATTRIBUTES    0.994624\n","TMIN_ATTRIBUTES    0.994398\n","DAPR               0.998796\n","MDPR               0.999923\n","WESD               0.999998\n","SNWD_ATTRIBUTES    0.999662\n","dtype: float64"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["(weather_data.isnull().sum())/weather_data.shape[0]"]},{"cell_type":"markdown","metadata":{},"source":["#### 2. Unique Countries\n","\n","This code retrieves the unique countries or regions from the `weather_data` DataFrame's 'Country/Region' column. It provides a distinct list of countries or regions present in the dataset."]},{"cell_type":"code","execution_count":6,"metadata":{"trusted":true},"outputs":[],"source":["country = weather_data['Country/Region'].unique()"]},{"cell_type":"code","execution_count":7,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["['Comoros',\n"," 'Georgia',\n"," 'Nepal',\n"," 'Philippines',\n"," 'Monaco',\n"," 'US',\n"," 'Australia',\n"," 'Namibia',\n"," 'Saint Lucia',\n"," 'Lebanon',\n"," 'Zambia',\n"," 'Malaysia',\n"," 'Peru',\n"," 'Kenya',\n"," 'Belarus',\n"," 'Iceland',\n"," 'Lesotho',\n"," 'Venezuela',\n"," 'Albania',\n"," 'Tanzania',\n"," 'Greece',\n"," 'Barbados',\n"," 'Singapore',\n"," 'Switzerland',\n"," 'Sri Lanka',\n"," 'China',\n"," 'Gabon',\n"," 'Guinea-Bissau',\n"," 'Congo (Brazzaville)',\n"," 'United Arab Emirates',\n"," 'Tajikistan',\n"," 'Syria',\n"," 'Lithuania',\n"," 'Paraguay',\n"," 'Romania',\n"," 'Maldives',\n"," 'Jamaica',\n"," 'Kuwait',\n"," 'Finland',\n"," 'Argentina',\n"," 'Ethiopia',\n"," 'Japan',\n"," 'Cameroon',\n"," 'Bhutan',\n"," 'Botswana',\n"," 'Pakistan',\n"," 'Brazil',\n"," 'Madagascar',\n"," 'Eritrea',\n"," 'Liberia',\n"," 'Mali',\n"," 'Thailand',\n"," 'Egypt',\n"," 'Ireland',\n"," 'Belgium',\n"," 'Luxembourg',\n"," 'Fiji',\n"," 'Italy',\n"," 'Greenland',\n"," 'Antigua and Barbuda',\n"," 'Saint Vincent and the Grenadines',\n"," 'Andorra',\n"," 'Guinea',\n"," 'Nigeria',\n"," 'Ecuador',\n"," 'Guatemala',\n"," 'Afghanistan',\n"," 'Suriname',\n"," 'Djibouti',\n"," 'Uganda',\n"," 'Niger',\n"," 'Israel',\n"," 'Russia',\n"," 'Chile',\n"," 'Mexico',\n"," 'Seychelles',\n"," 'Bosnia and Herzegovina',\n"," 'Montenegro',\n"," 'Trinidad and Tobago',\n"," 'Togo',\n"," 'Panama',\n"," 'Denmark',\n"," 'Malta',\n"," 'Sierra Leone',\n"," 'Bahamas',\n"," 'Taiwan',\n"," 'Kyrgyzstan',\n"," 'South Africa',\n"," 'Sao Tome and Principe',\n"," 'New Zealand',\n"," 'France',\n"," 'Qatar',\n"," 'Angola',\n"," 'Belize',\n"," 'Azerbaijan',\n"," 'San Marino',\n"," 'Saudi Arabia',\n"," 'Serbia',\n"," 'Turkey',\n"," 'Cuba',\n"," 'Nicaragua',\n"," 'Uruguay',\n"," 'Jordan',\n"," 'Timor-Leste',\n"," 'Grenada',\n"," 'Slovenia',\n"," 'Portugal',\n"," 'Western Sahara',\n"," 'Costa Rica',\n"," 'Mauritius',\n"," 'Dominica',\n"," 'Bolivia',\n"," 'Cambodia',\n"," 'Austria',\n"," 'Poland',\n"," 'Czechia',\n"," 'India',\n"," 'Somalia',\n"," 'Algeria',\n"," 'Brunei',\n"," 'Latvia',\n"," 'Gambia',\n"," 'Uzbekistan',\n"," 'Armenia',\n"," 'Slovakia',\n"," 'North Macedonia',\n"," 'Guyana',\n"," 'Cyprus',\n"," 'United Kingdom',\n"," \"Cote d'Ivoire\",\n"," 'Honduras',\n"," 'Mozambique',\n"," 'Oman',\n"," 'Iran',\n"," 'Mongolia',\n"," 'Hungary',\n"," 'West Bank and Gaza',\n"," 'Bahrain',\n"," 'Chad',\n"," 'Kazakhstan',\n"," 'Holy See',\n"," 'Congo (Kinshasa)',\n"," 'Burkina Faso',\n"," 'Dominican Republic',\n"," 'Ghana',\n"," 'Zimbabwe',\n"," 'Sudan',\n"," 'Benin',\n"," 'Estonia',\n"," 'Haiti',\n"," 'Indonesia',\n"," 'Saint Kitts and Nevis',\n"," 'Netherlands',\n"," 'Croatia',\n"," 'Canada']"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["list(country)"]},{"cell_type":"markdown","metadata":{},"source":["#### 3. Unique Stations\n","\n","This code calculates and returns the number of unique stations in the 'STATION' column of the `weather_data` DataFrame. It provides the count of distinct weather monitoring stations in the dataset."]},{"cell_type":"code","execution_count":8,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["5152"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["len(weather_data['STATION'].unique())"]},{"cell_type":"markdown","metadata":{},"source":["#### 4. Snow Depth Counts\n","\n","This code counts the occurrences of different values in the 'SNWD' column of the `weather_data` DataFrame. It provides a summary of how many times each unique value appears in the 'SNWD' column."]},{"cell_type":"code","execution_count":9,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["SNWD\n","0.0      113541\n","10.0       9041\n","20.0       3196\n","30.0       2483\n","150.0      1509\n","          ...  \n","28.7          1\n","27.6          1\n","29.1          1\n","26.8          1\n","6.0           1\n","Name: count, Length: 760, dtype: int64"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["weather_data['SNWD'].value_counts()"]},{"cell_type":"markdown","metadata":{},"source":["#### 5. Snowfall Counts\n","\n","This code counts the occurrences of different values in the 'SNOW' column of the `weather_data` DataFrame. It provides a summary of how many times each unique value appears in the 'SNOW' column, indicating the frequency of snowfall."]},{"cell_type":"code","execution_count":10,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["SNOW\n","0.0      93958\n","10.0      1113\n","20.0       753\n","30.0       506\n","5.0        480\n","         ...  \n","11.0         1\n","228.0        1\n","238.0        1\n","194.0        1\n","258.0        1\n","Name: count, Length: 242, dtype: int64"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["weather_data['SNOW'].value_counts()"]},{"cell_type":"markdown","metadata":{},"source":["#### 6. The values of Longitude and Latitude are 92% null so to handle that we have tried to fill null values by filling with original latitude and longitude of each country. We have done that because we wanted to use the whole dataset for my model but then we have decided to work only on a particular country, so we have removed this code."]},{"cell_type":"code","execution_count":11,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["'from geopy.exc import GeocoderTimedOut\\nfrom geopy.geocoders import Nominatim'"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["'''from geopy.exc import GeocoderTimedOut\n","from geopy.geocoders import Nominatim'''"]},{"cell_type":"code","execution_count":12,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["\"data = {'Country':country}\""]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["'''data = {'Country':country}'''"]},{"cell_type":"code","execution_count":13,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["'longitude = []\\nlatitude = []\\n   \\ndef findGeocode(country):\\n       \\n    try:\\n          \\n        geolocator = Nominatim(user_agent=\"your_app_name\")\\n\\n        return geolocator.geocode(country)\\n      \\n    except GeocoderTimedOut:\\n          \\n        return findGeocode(country)    \\n   \\nfor i in (data[\\'Country\\']):\\n      \\n    if findGeocode(i) != None:\\n           \\n        loc = findGeocode(i)\\n      \\n        latitude.append(loc.latitude)\\n        longitude.append(loc.longitude)\\n\\n    else:\\n        latitude.append(np.nan)\\n        longitude.append(np.nan)'"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["'''longitude = []\n","latitude = []\n","   \n","def findGeocode(country):\n","       \n","    try:\n","          \n","        geolocator = Nominatim(user_agent=\"your_app_name\")\n","\n","        return geolocator.geocode(country)\n","      \n","    except GeocoderTimedOut:\n","          \n","        return findGeocode(country)    \n","   \n","for i in (data['Country']):\n","      \n","    if findGeocode(i) != None:\n","           \n","        loc = findGeocode(i)\n","      \n","        latitude.append(loc.latitude)\n","        longitude.append(loc.longitude)\n","\n","    else:\n","        latitude.append(np.nan)\n","        longitude.append(np.nan)'''"]},{"cell_type":"code","execution_count":14,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["\"weather_data[weather_data['Country/Region'] == 'India']['LONGITUDE'].fillna(longitude[0])\""]},"execution_count":14,"metadata":{},"output_type":"execute_result"}],"source":["'''weather_data[weather_data['Country/Region'] == 'India']['LONGITUDE'].fillna(longitude[0])'''"]},{"cell_type":"code","execution_count":15,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["\"x = weather_data['Country/Region'] == 'India'\\nweather_data.loc[x]\""]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["'''x = weather_data['Country/Region'] == 'India'\n","weather_data.loc[x]'''"]},{"cell_type":"code","execution_count":16,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["\"for country_name, lon, lat in zip(country, longitude, latitude):\\n    mask = weather_data['Country/Region'] == country_name\\n    \\n    if mask.any():\\n\\n        weather_data.loc[mask, 'LONGITUDE'] = lon\\n        weather_data.loc[mask, 'LATITUDE'] = lat\""]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["'''for country_name, lon, lat in zip(country, longitude, latitude):\n","    mask = weather_data['Country/Region'] == country_name\n","    \n","    if mask.any():\n","\n","        weather_data.loc[mask, 'LONGITUDE'] = lon\n","        weather_data.loc[mask, 'LATITUDE'] = lat'''"]},{"cell_type":"markdown","metadata":{},"source":["#### 7. India Weather Data\n","\n","This code creates a new DataFrame, `weather_india`, by selecting rows from the `weather_data` DataFrame where the 'Country/Region' is 'India'. It isolates weather data specifically related to India for further analysis."]},{"cell_type":"code","execution_count":17,"metadata":{"trusted":true},"outputs":[],"source":["weather_india = weather_data[weather_data['Country/Region']=='India'].copy()"]},{"cell_type":"markdown","metadata":{},"source":["#### 8. Weather Data Cleanup\n","\n","This code modifies the `weather_india` DataFrame by removing several columns, including 'ELEVATION', 'PRCP_ATTRIBUTES', 'TAVG_ATTRIBUTES', 'TMAX_ATTRIBUTES', 'TMIN_ATTRIBUTES', 'DAPR', 'MDPR', 'WESD', 'SNWD_ATTRIBUTES', 'Year', and 'SNOW'. It performs data cleanup by eliminating unnecessary or redundant information for analysis."]},{"cell_type":"code","execution_count":18,"metadata":{"trusted":true},"outputs":[],"source":["weather_india_final = weather_india.drop(['ELEVATION', 'PRCP_ATTRIBUTES','TAVG_ATTRIBUTES','TMAX_ATTRIBUTES','TMIN_ATTRIBUTES','DAPR','MDPR','WESD','SNWD_ATTRIBUTES','Year','SNOW'], axis=1)"]},{"cell_type":"code","execution_count":19,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>STATION</th>\n","      <th>Country/Region</th>\n","      <th>DATE</th>\n","      <th>Month</th>\n","      <th>Day</th>\n","      <th>PRCP</th>\n","      <th>SNWD</th>\n","      <th>TAVG</th>\n","      <th>TMAX</th>\n","      <th>TMIN</th>\n","      <th>LATITUDE</th>\n","      <th>LONGITUDE</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>589897</th>\n","      <td>IN017111200</td>\n","      <td>India</td>\n","      <td>22-01-2020</td>\n","      <td>1</td>\n","      <td>22</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>22.5</td>\n","      <td>NaN</td>\n","      <td>16.1</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>589898</th>\n","      <td>IN017111200</td>\n","      <td>India</td>\n","      <td>23-01-2020</td>\n","      <td>1</td>\n","      <td>23</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>24.1</td>\n","      <td>NaN</td>\n","      <td>18.5</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>589899</th>\n","      <td>IN017111200</td>\n","      <td>India</td>\n","      <td>24-01-2020</td>\n","      <td>1</td>\n","      <td>24</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>23.2</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>589900</th>\n","      <td>IN017111200</td>\n","      <td>India</td>\n","      <td>25-01-2020</td>\n","      <td>1</td>\n","      <td>25</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>21.4</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>589901</th>\n","      <td>IN017111200</td>\n","      <td>India</td>\n","      <td>26-01-2020</td>\n","      <td>1</td>\n","      <td>26</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>21.3</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>612899</th>\n","      <td>IN004102500</td>\n","      <td>India</td>\n","      <td>23-07-2020</td>\n","      <td>7</td>\n","      <td>23</td>\n","      <td>6.1</td>\n","      <td>NaN</td>\n","      <td>28.3</td>\n","      <td>NaN</td>\n","      <td>24.8</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>612900</th>\n","      <td>IN004102500</td>\n","      <td>India</td>\n","      <td>24-07-2020</td>\n","      <td>7</td>\n","      <td>24</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>25.7</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>612901</th>\n","      <td>IN004102500</td>\n","      <td>India</td>\n","      <td>25-07-2020</td>\n","      <td>7</td>\n","      <td>25</td>\n","      <td>72.9</td>\n","      <td>NaN</td>\n","      <td>28.9</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>612902</th>\n","      <td>IN004102500</td>\n","      <td>India</td>\n","      <td>26-07-2020</td>\n","      <td>7</td>\n","      <td>26</td>\n","      <td>0.0</td>\n","      <td>NaN</td>\n","      <td>31.3</td>\n","      <td>35.8</td>\n","      <td>27.6</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>612903</th>\n","      <td>IN004102500</td>\n","      <td>India</td>\n","      <td>27-07-2020</td>\n","      <td>7</td>\n","      <td>27</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","      <td>30.6</td>\n","      <td>NaN</td>\n","      <td>28.6</td>\n","      <td>NaN</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>23007 rows × 12 columns</p>\n","</div>"],"text/plain":["            STATION Country/Region        DATE  Month  Day  PRCP  SNWD  TAVG  \\\n","589897  IN017111200          India  22-01-2020      1   22   NaN   NaN  22.5   \n","589898  IN017111200          India  23-01-2020      1   23   NaN   NaN  24.1   \n","589899  IN017111200          India  24-01-2020      1   24   NaN   NaN  23.2   \n","589900  IN017111200          India  25-01-2020      1   25   NaN   NaN  21.4   \n","589901  IN017111200          India  26-01-2020      1   26   NaN   NaN  21.3   \n","...             ...            ...         ...    ...  ...   ...   ...   ...   \n","612899  IN004102500          India  23-07-2020      7   23   6.1   NaN  28.3   \n","612900  IN004102500          India  24-07-2020      7   24   0.0   NaN  25.7   \n","612901  IN004102500          India  25-07-2020      7   25  72.9   NaN  28.9   \n","612902  IN004102500          India  26-07-2020      7   26   0.0   NaN  31.3   \n","612903  IN004102500          India  27-07-2020      7   27   NaN   NaN  30.6   \n","\n","        TMAX  TMIN  LATITUDE  LONGITUDE  \n","589897   NaN  16.1       NaN        NaN  \n","589898   NaN  18.5       NaN        NaN  \n","589899   NaN   NaN       NaN        NaN  \n","589900   NaN   NaN       NaN        NaN  \n","589901   NaN   NaN       NaN        NaN  \n","...      ...   ...       ...        ...  \n","612899   NaN  24.8       NaN        NaN  \n","612900   NaN   NaN       NaN        NaN  \n","612901   NaN   NaN       NaN        NaN  \n","612902  35.8  27.6       NaN        NaN  \n","612903   NaN  28.6       NaN        NaN  \n","\n","[23007 rows x 12 columns]"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["weather_india_final"]},{"cell_type":"markdown","metadata":{},"source":["#### 9. Missing Snow Depth Data\n","\n","This code calculates and reports the number of missing values (null values) in the 'SNWD' column of the `weather_india_final` DataFrame. It provides information on the count of missing entries in the snow depth data."]},{"cell_type":"code","execution_count":20,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["23007"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["weather_india_final['SNWD'].isnull().sum()"]},{"cell_type":"markdown","metadata":{},"source":["#### 10. Missing Precipitation Data\n","\n","This code calculates and reports the number of missing values (null values) in the 'PRCP' column of the `weather_india_final` DataFrame. It provides information on the count of missing entries in the precipitation data."]},{"cell_type":"code","execution_count":21,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["15145"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["weather_india_final['PRCP'].isnull().sum()"]},{"cell_type":"markdown","metadata":{},"source":["#### 11. Missing Minimum Temperature Data\n","\n","This code calculates and reports the number of missing values (null values) in the 'TMIN' column of the `weather_india_final` DataFrame. It provides information on the count of missing entries in the minimum temperature data."]},{"cell_type":"code","execution_count":22,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["4037"]},"execution_count":22,"metadata":{},"output_type":"execute_result"}],"source":["weather_india_final['TMIN'].isnull().sum()"]},{"cell_type":"markdown","metadata":{},"source":["### 12. Data Column Removal\n","\n","This code modifies the `weather_india_final` DataFrame by removing specific columns, including 'SNWD,' 'LATITUDE,' 'LONGITUDE,' 'TMAX,' 'Country/Region,' 'Day,' and 'Month.' It streamlines the dataset by eliminating unnecessary columns for analysis."]},{"cell_type":"code","execution_count":23,"metadata":{"trusted":true},"outputs":[],"source":["weather_india_final = weather_india_final.drop(['SNWD','LATITUDE','LONGITUDE','TMAX','Country/Region','Day','Month'],axis=1)"]},{"cell_type":"markdown","metadata":{},"source":["#### 13. Unique Weather Stations\n","\n","This code extracts the unique weather stations from the 'STATION' column of the `weather_india_final` DataFrame. It provides a list of distinct weather monitoring stations present in the dataset."]},{"cell_type":"code","execution_count":24,"metadata":{"trusted":true},"outputs":[],"source":["stat = weather_india_final['STATION'].unique()"]},{"cell_type":"markdown","metadata":{},"source":["#### 14. Removing Weather Stations\n","\n","This code identifies and creates a list of weather stations (`remove_stat`) with fewer than 50 data entries in the `weather_india_final` DataFrame. These stations may be removed to ensure data quality or focus on stations with sufficient data for analysis."]},{"cell_type":"code","execution_count":25,"metadata":{"trusted":true},"outputs":[],"source":["remove_stat = []\n","for i in stat:\n","    if len(weather_india_final[weather_india_final['STATION']==i])<50:\n","        remove_stat.append(i)"]},{"cell_type":"code","execution_count":26,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["['IN009100200',\n"," 'IN005030100',\n"," 'IN012180300',\n"," 'IN011330900',\n"," 'IN019070100',\n"," 'IN024059900',\n"," 'IN014020800']"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["remove_stat"]},{"cell_type":"markdown","metadata":{},"source":["#### 15. Removing Selected Stations\n","\n","This code removes rows from the `weather_india_final` DataFrame where the 'STATION' value matches the stations identified in the `remove_stat` list. It eliminates data associated with the selected weather stations from the dataset."]},{"cell_type":"code","execution_count":27,"metadata":{"trusted":true},"outputs":[],"source":["weather_india_final.drop(weather_india_final[weather_india_final.STATION.isin(remove_stat)].index, axis = 0, inplace = True)"]},{"cell_type":"code","execution_count":28,"metadata":{"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>STATION</th>\n","      <th>DATE</th>\n","      <th>PRCP</th>\n","      <th>TAVG</th>\n","      <th>TMIN</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>589897</th>\n","      <td>IN017111200</td>\n","      <td>22-01-2020</td>\n","      <td>NaN</td>\n","      <td>22.5</td>\n","      <td>16.1</td>\n","    </tr>\n","    <tr>\n","      <th>589898</th>\n","      <td>IN017111200</td>\n","      <td>23-01-2020</td>\n","      <td>NaN</td>\n","      <td>24.1</td>\n","      <td>18.5</td>\n","    </tr>\n","    <tr>\n","      <th>589899</th>\n","      <td>IN017111200</td>\n","      <td>24-01-2020</td>\n","      <td>NaN</td>\n","      <td>23.2</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>589900</th>\n","      <td>IN017111200</td>\n","      <td>25-01-2020</td>\n","      <td>NaN</td>\n","      <td>21.4</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>589901</th>\n","      <td>IN017111200</td>\n","      <td>26-01-2020</td>\n","      <td>NaN</td>\n","      <td>21.3</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>612899</th>\n","      <td>IN004102500</td>\n","      <td>23-07-2020</td>\n","      <td>6.1</td>\n","      <td>28.3</td>\n","      <td>24.8</td>\n","    </tr>\n","    <tr>\n","      <th>612900</th>\n","      <td>IN004102500</td>\n","      <td>24-07-2020</td>\n","      <td>0.0</td>\n","      <td>25.7</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>612901</th>\n","      <td>IN004102500</td>\n","      <td>25-07-2020</td>\n","      <td>72.9</td>\n","      <td>28.9</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>612902</th>\n","      <td>IN004102500</td>\n","      <td>26-07-2020</td>\n","      <td>0.0</td>\n","      <td>31.3</td>\n","      <td>27.6</td>\n","    </tr>\n","    <tr>\n","      <th>612903</th>\n","      <td>IN004102500</td>\n","      <td>27-07-2020</td>\n","      <td>NaN</td>\n","      <td>30.6</td>\n","      <td>28.6</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>22980 rows × 5 columns</p>\n","</div>"],"text/plain":["            STATION        DATE  PRCP  TAVG  TMIN\n","589897  IN017111200  22-01-2020   NaN  22.5  16.1\n","589898  IN017111200  23-01-2020   NaN  24.1  18.5\n","589899  IN017111200  24-01-2020   NaN  23.2   NaN\n","589900  IN017111200  25-01-2020   NaN  21.4   NaN\n","589901  IN017111200  26-01-2020   NaN  21.3   NaN\n","...             ...         ...   ...   ...   ...\n","612899  IN004102500  23-07-2020   6.1  28.3  24.8\n","612900  IN004102500  24-07-2020   0.0  25.7   NaN\n","612901  IN004102500  25-07-2020  72.9  28.9   NaN\n","612902  IN004102500  26-07-2020   0.0  31.3  27.6\n","612903  IN004102500  27-07-2020   NaN  30.6  28.6\n","\n","[22980 rows x 5 columns]"]},"execution_count":28,"metadata":{},"output_type":"execute_result"}],"source":["weather_india_final"]},{"cell_type":"markdown","metadata":{},"source":["#### 16. Station Label Encoding\n","\n","This code utilizes a label encoder to convert the 'STATION' column in the `weather_india_final` DataFrame into numeric labels. It assigns unique numerical values to each station name for further analysis.#### By using Label Encoding I am just giving a unique number to each unique station."]},{"cell_type":"code","execution_count":29,"metadata":{"trusted":true},"outputs":[],"source":["label_encoder = preprocessing.LabelEncoder()\n","weather_india_final['STATION']= label_encoder.fit_transform(weather_india_final['STATION'])"]},{"cell_type":"markdown","metadata":{},"source":["#### 17. Pairwise Relationships\n","\n","This code generates a pairplot using Seaborn (`sns`) to visualize pairwise relationships between variables in the `weather_india_final` DataFrame. The plot is colored by the 'DATE' variable to highlight patterns or trends over time."]},{"cell_type":"code","execution_count":30,"metadata":{"trusted":true},"outputs":[{"data":{"text/plain":["<seaborn.axisgrid.PairGrid at 0x7f373e1177c0>"]},"execution_count":30,"metadata":{},"output_type":"execute_result"}],"source":["sns.pairplot(weather_india_final,hue='DATE')"]},{"cell_type":"markdown","metadata":{},"source":["### 18.  Date Index Setting\n","\n","This code sets the 'DATE' column as the index for the `weather_india_final` DataFrame. It uses the 'DATE' column as the primary index for organizing and accessing the data."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["weather_india_final.set_index('DATE',inplace = True)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["weather_india_final"]},{"cell_type":"markdown","metadata":{},"source":["#### 19. Precipitation Value Counts\n","\n","This code calculates the count of each unique value in the 'PRCP' column of the `weather_india_final` DataFrame. It then filters and stores values that occur more than 100 times in the `result1` variable. The code repeats the same operation twice."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["count_1 = weather_india_final['PRCP'].value_counts()\n","result1 = count_1[count_1>100]\n","result1"]},{"cell_type":"markdown","metadata":{},"source":["#### 20. Precipitation Data Handling\n","\n","This code fills missing values in the 'PRCP' column of the `weather_india_final` DataFrame. It first uses forward-fill (`method='ffill'`) to fill missing values, and then, if any remain, it fills them with 0. This ensures completeness of precipitation data. A further rechecking is done for exceptions."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["weather_india_final['PRCP'].fillna(method = 'ffill',inplace=True)\n","weather_india_final['PRCP'].fillna(0,inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["weather_india_final['PRCP'].isnull().sum()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["weather_india_final['PRCP'].value_counts()"]},{"cell_type":"markdown","metadata":{},"source":["#### 21. Minimum Temperature Plot\n","\n","This code creates a time series plot of the 'TMIN' (minimum temperature) data from the `weather_india_final` DataFrame. It visualizes the variation in minimum temperatures over time, with a specified figure size."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["weather_india_final['TMIN'].plot(figsize=(20, 6))"]},{"cell_type":"markdown","metadata":{},"source":["#### 22. Summary Statistics for Minimum Temperature\n","\n","This code calculates basic summary statistics for the 'TMIN' (minimum temperature) data in the `weather_india_final` DataFrame. It includes the mean, median, and mode of the minimum temperature values."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["weather_india_final['TMIN'].mean()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["weather_india_final['TMIN'].median()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["weather_india_final['TMIN'].mode()"]},{"cell_type":"markdown","metadata":{},"source":["#### 23. Month-Wise TAVGs for India\n","\n","Here, we plotted the monthwise TAVGs for India, i.e., the plot for for avg temperature throughout India on every date, monthwise."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["wi = pd.DataFrame(columns=['Date', 'TAVG'])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["wi['Date'] = weather_india_final.groupby(['DATE'])['TAVG'].mean().index\n","wi['TAVG'] = weather_india_final.groupby(['DATE'])['TAVG'].mean().values\n","wi"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["wi.set_index('Date',inplace=True)\n","wi.index = pd.to_datetime(wi.index, format=\"%d-%m-%Y\")"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["# Create subplots for each month\n","fig, axes = plt.subplots(1, 2, figsize=(15, 4))\n","count = 0\n","\n","for i in range(1, 8):  # Month numbers from 1 to 7\n","    temp = wi[wi.index.month == i]\n","    ax = axes[count]\n","    ax.plot(temp.index, temp['TAVG'], label='TAVG')\n","    ax.set_title(calendar.month_name[i])\n","    ax.tick_params(axis='x', rotation=45)\n","    \n","    if i == 7:\n","        ax.legend(loc='upper left', bbox_to_anchor=(1.0, 1.05))\n","    \n","    count += 1\n","    \n","    if count == 2 or i == 7:\n","        ax.legend(loc='upper left', bbox_to_anchor=(1.0, 1.05))\n","        plt.tight_layout()\n","        plt.show()\n","        if i != 7:\n","            fig, axes = plt.subplots(1, 2, figsize=(15, 4))\n","            count = 0"]},{"cell_type":"markdown","metadata":{},"source":["#### 24. Handling Missing Minimum Temperature Data\n","\n","If the mean is approximately 20.9490, the median is 22.5, and the mode is 25, this code fills missing values in the 'TMIN' (minimum temperature) column of the `weather_india_final` DataFrame. It replaces missing values with the median temperature to address data gaps."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["weather_india_final['TMIN'].fillna(weather_india_final['TMIN'].median(),inplace=True)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["weather_india_final"]},{"cell_type":"markdown","metadata":{},"source":["#### 25. Plotting Violinplots and Boxplots to analyze how data is distributed of features 'PRCP', 'TMIN', 'TMAX'."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["sns.violinplot(x=weather_india_final['PRCP'])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["sns.boxplot(x=weather_india_final['TAVG'])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["sns.violinplot(x=weather_india_final['TAVG'])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["sns.boxplot(x=weather_india_final['TMIN'])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["sns.violinplot(x=weather_india_final['TMIN'])"]},{"cell_type":"markdown","metadata":{},"source":["#### 26. Date Index Conversion\n","\n","This code converts the index of the `weather_india_final` DataFrame to a datetime format using `pd.to_datetime()`. It enables time-based analysis and operations on the dataset."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["weather_india_final.index = pd.to_datetime(weather_india_final.index)"]},{"cell_type":"markdown","metadata":{},"source":["#### 27. Temperature Trends\n","\n","This code generates a line plot to visualize trends in both average temperature ('TAVG') and minimum temperature ('TMIN') from the `weather_india_final` DataFrame. It provides insights into temperature variations over time."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["weather_india_final[['TAVG','TMIN']].plot()"]},{"cell_type":"markdown","metadata":{},"source":["#### 28. Creating Target Column\n","\n","This code creates a new column named 'Target' in the `weather_india_final` DataFrame by shifting the 'TAVG' (average temperature) data one step forward. It is commonly used for time-series forecasting tasks."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["weather_india_final['Target'] = weather_india_final.shift(-1)['TAVG']"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["weather_india_final = weather_india_final.iloc[:-1,:].copy()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["weather_india_final"]},{"cell_type":"markdown","metadata":{},"source":["#### 29. Correlation Heatmap\n","\n","This code generates a heatmap using Seaborn (`sns`) to visualize the correlation matrix of variables in the `weather_india_final` DataFrame. It helps identify relationships between variables."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["sns.heatmap(weather_india_final.corr())"]},{"cell_type":"markdown","metadata":{},"source":["#### 30. Data for Particular Station\n","\n","This code filters the `weather_india_final` DataFrame to extract data specifically for Station 85. It allows for focused analysis on a particular weather station.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["weather_india_final[weather_india_final['STATION'] == 85]"]},{"cell_type":"markdown","metadata":{},"source":["#### 31. Unique Stations\n","\n","This code extracts and displays the unique weather station identifiers ('STATION') from the `weather_india_final` DataFrame. It provides a list of distinct station IDs."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["stations = weather_india_final['STATION'].unique()\n","stations"]},{"cell_type":"markdown","metadata":{},"source":["#### 32. Correlation Heatmap with Annotations\n","\n","This code generates a heatmap using Seaborn (`sns`) to visualize the correlation matrix of variables in the `weather_india_final` DataFrame. It includes annotations and uses the 'coolwarm' color map to highlight correlations between variables."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["sns.heatmap(weather_india_final.corr(),annot=True, cmap='coolwarm')"]},{"cell_type":"markdown","metadata":{},"source":["## 3. Regression Models"]},{"cell_type":"markdown","metadata":{},"source":["For predictions, we have the first 6 months of data in our training set and the last month, which is the seventh month, in our test data. Our model's task is to provide the average temperature for the next day for all the stations present in India during this seventh month."]},{"cell_type":"markdown","metadata":{},"source":["### 1. Linear Regression"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["Linear_metrics = pd.DataFrame(columns=['Station', 'MAE', 'MSE', 'RMSE', 'Accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["stations = sorted(weather_india_final['STATION'].unique())\n","fig, ax = plt.subplots(1, 6, figsize=(22, 3))\n","fig.suptitle('Linear Regression')\n","for i, station in enumerate(stations):\n","    df = weather_india_final[weather_india_final['STATION'] == station].copy() \n","    df.drop(['STATION'], axis=1, inplace=True)\n","    \n","    train = df.loc[:'2020-06-30']\n","    X_train = train.drop('Target', axis=1)\n","    y_train = train['Target']\n","    \n","\n","    test = df.loc['2020-07-01':]\n","    X_test = test.drop(['Target'], axis=1)\n","    y_test = test['Target']\n","    \n","    sc = StandardScaler()\n","    X_train_scaled = sc.fit_transform(X_train)\n","    X_test_scaled = sc.transform(X_test)\n","    \n","    Linear = LinearRegression()\n","    Linear.fit(X_train_scaled, y_train)\n","    \n","    preds = Linear.predict(X_test_scaled)\n","\n","    metrics = {'Station': i, 'MAE': mean_absolute_error(y_test, preds), 'MSE': mean_squared_error(y_test, preds),\n","    'RMSE': np.sqrt(mean_squared_error(y_test, preds)), 'Accuracy': str(round(100 - (np.mean(np.abs(y_test - preds) / y_test) * 100), 2)) + '%'}\n","\n","    Linear_metrics = pd.concat([Linear_metrics, pd.DataFrame([metrics])], ignore_index=True)\n","    \n","    combined = pd.concat([y_test, pd.Series(preds, index=test.index)], axis=1)\n","    combined.columns = ['Actual', 'Predictions']\n","    \n","    count = i % 6\n","    ax[count].plot(combined.index, combined['Actual'], label='Actual')\n","    ax[count].plot(combined.index, combined['Predictions'], label='Predicted')\n","    ax[count].set_title(f\"Station {i}\")\n","    ax[count].tick_params(axis='x', rotation=45)\n","    \n","    if (count == 5) or (i == (len(stations) - 1)):\n","        plt.legend(loc='upper left', bbox_to_anchor=(1.0, 1.05))\n","        plt.tight_layout()\n","        plt.show()\n","        \n","        if i != (len(stations) - 1):\n","            fig, ax = plt.subplots(1, 6, figsize=(22, 3))"]},{"cell_type":"markdown","metadata":{},"source":["Linear_metrics"]},{"cell_type":"markdown","metadata":{},"source":["### 2. Polynomial Regression"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["Poly_metrics = pd.DataFrame(columns=['Station', 'MAE', 'MSE', 'RMSE', 'Accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["params = {\n","    'polynomialfeatures__degree': [2, 3, 4],  # Adjust the degrees as needed\n","    'linearregression__fit_intercept': [True, False],\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["stations = sorted(weather_india_final['STATION'].unique())\n","fig, ax = plt.subplots(1, 6, figsize=(22, 3))\n","fig.suptitle('Polynomial Regression')\n","for i, station in enumerate(stations):\n","    df = weather_india_final[weather_india_final['STATION'] == station].copy() \n","    df.drop(['STATION'], axis=1, inplace=True)\n","    \n","    train = df.loc[:'2020-06-30']\n","    X_train = train.drop('Target', axis=1)\n","    y_train = train['Target']\n","    \n","\n","    test = df.loc['2020-07-01':]\n","    X_test = test.drop(['Target'], axis=1)\n","    y_test = test['Target']\n","    \n","    sc = StandardScaler()\n","    X_train_scaled = sc.fit_transform(X_train)\n","    X_test_scaled = sc.transform(X_test)\n","    \n","    polyreg = make_pipeline(PolynomialFeatures(), LinearRegression())\n","    \n","    grid_search = GridSearchCV(estimator=polyreg, param_grid=params, scoring='neg_mean_squared_error', cv=5)\n","    grid_search.fit(X_train_scaled, y_train)\n","    \n","    preds = grid_search.predict(X_test_scaled)\n","\n","    metrics = {'Station': i, 'MAE': mean_absolute_error(y_test, preds), 'MSE': mean_squared_error(y_test, preds),\n","    'RMSE': np.sqrt(mean_squared_error(y_test, preds)), 'Accuracy': str(round(100 - (np.mean(np.abs(y_test - preds) / y_test) * 100), 2)) + '%'}\n","\n","    Poly_metrics = pd.concat([Poly_metrics, pd.DataFrame([metrics])], ignore_index=True)\n","    \n","    combined = pd.concat([y_test, pd.Series(preds, index=test.index)], axis=1)\n","    combined.columns = ['Actual', 'Predictions']\n","    print(f\"Best Params for Station {i} : {grid_search.best_params_}\")\n","\n","    count = i % 6\n","    ax[count].plot(combined.index, combined['Actual'], label='Actual')\n","    ax[count].plot(combined.index, combined['Predictions'], label='Predicted')\n","    ax[count].set_title(f'Station {station}')\n","    ax[count].tick_params(axis='x', rotation=45)\n","    \n","    if (count == 5) or (i == (len(stations) - 1)):\n","        plt.legend(loc='upper left', bbox_to_anchor=(1.0, 1.05))\n","        plt.tight_layout()\n","        plt.show()\n","        \n","        if i != (len(stations) - 1):\n","            fig, ax = plt.subplots(1, 6, figsize=(22, 3))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["Poly_metrics"]},{"cell_type":"markdown","metadata":{},"source":["### 3. SGD Regression"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["sgd_metrics = pd.DataFrame(columns=['Station', 'MAE', 'MSE', 'RMSE', 'Accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["params = {\n","    'alpha': [0.0006, 0.0009, 0.0003, 0.001, 0.0015, 0.002, 0.1, 0.3, 0.6, 0.005, 0.003, 0.09, 0.06, 0.006, 1, 5, 8, 10, 20],\n","    'solver': ['auto', 'svd', 'cholesky', 'saga', 'lsqr', 'sparse_cg', 'sag']\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["stations = sorted(weather_india_final['STATION'].unique())\n","fig, ax = plt.subplots(1, 6, figsize=(22, 3))\n","fig.suptitle('SGD Regression')\n","\n","for i, station in enumerate(stations):\n","    df = weather_india_final[weather_india_final['STATION'] == station].copy()\n","    df.drop(['STATION'], axis=1, inplace=True)\n","    \n","    train = df.loc[:'2020-06-30']\n","    X_train = train.drop('Target', axis=1)\n","    y_train = train['Target']\n","    \n","    test = df.loc['2020-07-01':]\n","    X_test = test.drop(['Target'], axis=1)\n","    y_test = test['Target']\n","    \n","    sc = StandardScaler()\n","    X_train_scaled = sc.fit_transform(X_train)\n","    X_test_scaled = sc.transform(X_test)\n","    \n","    sgd_regressor = SGDRegressor()\n","    sgd_regressor.fit(X_train_scaled, y_train)\n","    \n","    preds = sgd_regressor.predict(X_test_scaled)\n","    \n","    metrics = {'Station': i, 'MAE': mean_absolute_error(y_test, preds), 'MSE': mean_squared_error(y_test, preds),\n","    'RMSE': np.sqrt(mean_squared_error(y_test, preds)), 'Accuracy': str(round(100 - (np.mean(np.abs(y_test - preds) / y_test) * 100), 2)) + '%'}\n","    \n","    sgd_metrics = pd.concat([sgd_metrics, pd.DataFrame([metrics])], ignore_index=True)\n","\n","    combined = pd.concat([y_test, pd.Series(preds, index=test.index)], axis=1)\n","    combined.columns = ['Actual', 'Predictions']\n","    \n","    count = i % 6\n","    ax[count].plot(combined.index, combined['Actual'], label='Actual')\n","    ax[count].plot(combined.index, combined['Predictions'], label='Predicted')\n","    ax[count].set_title(f'Station {station}')\n","    ax[count].tick_params(axis='x', rotation=45)\n","    \n","    if (count == 5) or (i == (len(stations) - 1)):\n","        plt.legend(loc='upper left', bbox_to_anchor=(1.0, 1.05))\n","        plt.tight_layout()\n","        plt.show()\n","        \n","        if i != (len(stations) - 1):\n","            fig, ax = plt.subplots(1, 6, figsize=(22, 3))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["sgd_metrics"]},{"cell_type":"markdown","metadata":{},"source":["### 4. Lasso Regression"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["lasso_metrics = pd.DataFrame(columns=['Station', 'MAE', 'MSE', 'RMSE', 'Accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["params_lasso = {\n","'alpha': [0.0006, 0.0009, 0.0003, 0.001, 0.0015, 0.002, 0.1, 0.3, 0.6, 0.005, 0.003, 0.09, 0.06, 0.006, 1, 5, 8, 10, 20],\n","'selection': ['cyclic', 'random'],\n","'max_iter': [100, 500, 1000],\n","'fit_intercept': [True, False]\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["\n","\n","stations = sorted(weather_india_final['STATION'].unique())\n","fig, ax = plt.subplots(1, 6, figsize=(22, 3))\n","fig.suptitle('Lasso Regression') # Updated title\n","\n","for i, station in enumerate(stations):\n","    df = weather_india_final[weather_india_final['STATION'] == station].copy()\n","    df.drop(['STATION'], axis=1, inplace=True)\n","\n","    train = df.loc[:'2020-06-30']\n","    X_train = train.drop('Target', axis=1)\n","    y_train = train['Target']\n","\n","    test = df.loc['2020-07-01':]\n","    X_test = test.drop(['Target'], axis=1)\n","    y_test = test['Target']\n","\n","    sc = StandardScaler()\n","    X_train_scaled = sc.fit_transform(X_train)\n","    X_test_scaled = sc.transform(X_test)\n","\n","    lasso = GridSearchCV(estimator=Lasso(), param_grid=params_lasso, scoring='neg_mean_squared_error', cv=5)\n","    lasso.fit(X_train_scaled, y_train)\n","\n","    preds = lasso.predict(X_test_scaled)\n","\n","    metrics = {'Station': i, 'MAE': mean_absolute_error(y_test, preds), 'MSE': mean_squared_error(y_test, preds),\n","    'RMSE': np.sqrt(mean_squared_error(y_test, preds)), 'Accuracy': str(round(100 - (np.mean(np.abs(y_test - preds) / y_test) * 100), 2)) + '%'}\n","\n","    lasso_metrics = pd.concat([lasso_metrics, pd.DataFrame([metrics])], ignore_index=True)\n","\n","    combined = pd.concat([y_test, pd.Series(preds, index=test.index)], axis=1)\n","    combined.columns = ['Actual', 'Predictions']\n","\n","    print(f'Best Params for Station {i} : {lasso.best_params_}')\n","\n","    count = i % 6\n","    ax[count].plot(combined.index, combined['Actual'], label='Actual')\n","    ax[count].plot(combined.index, combined['Predictions'], label='Predicted')\n","    ax[count].set_title(f'Station {station}')\n","    ax[count].tick_params(axis='x', rotation=45)\n","\n","    if (count == 5) or (i == (len(stations) - 1)):\n","        plt.legend(loc='upper left', bbox_to_anchor=(1.0, 1.05))\n","        plt.tight_layout()\n","        plt.show()\n","\n","        if i != (len(stations) - 1):\n","            fig, ax = plt.subplots(1, 6, figsize=(22, 3))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["lasso_metrics"]},{"cell_type":"markdown","metadata":{},"source":["### 5. Ridge Regression"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["Ridge_metrics = pd.DataFrame(columns=['Station', 'MAE', 'MSE', 'RMSE', 'Accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["params = {'alpha': [0.0006,0.0009,0.0003,0.001,0.0015,0.002,0.1,0.3,0.6,0.005,0.003,0.09,0.06,0.006,1,5,8,10,20],\n","          'solver' : ['auto', 'svd', 'cholesky', 'saga','lsqr', 'sparse_cg', 'sag']\n","         }"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["stations = sorted(weather_india_final['STATION'].unique())\n","fig, ax = plt.subplots(1, 6, figsize=(22, 3))\n","fig.suptitle('Ridge Regression')\n","for i, station in enumerate(stations):\n","    df = weather_india_final[weather_india_final['STATION'] == station].copy() \n","    df.drop(['STATION'], axis=1, inplace=True)\n","    \n","    train = df.loc[:'2020-06-30']\n","    X_train = train.drop('Target', axis=1)\n","    y_train = train['Target']\n","    \n","\n","    test = df.loc['2020-07-01':]\n","    X_test = test.drop(['Target'], axis=1)\n","    y_test = test['Target']\n","    \n","    sc = StandardScaler()\n","    X_train_scaled = sc.fit_transform(X_train)\n","    X_test_scaled = sc.transform(X_test)\n","    \n","    grid_search = GridSearchCV(estimator=Ridge(), param_grid=params, scoring='neg_mean_squared_error', cv=5)\n","    grid_search.fit(X_train_scaled, y_train)\n","    \n","    preds = grid_search.predict(X_test_scaled)\n","\n","    metrics = {'Station': i, 'MAE': mean_absolute_error(y_test, preds), 'MSE': mean_squared_error(y_test, preds),\n","    'RMSE': np.sqrt(mean_squared_error(y_test, preds)), 'Accuracy': str(round(100 - (np.mean(np.abs(y_test - preds) / y_test) * 100), 2)) + '%'}\n","\n","    Ridge_metrics = pd.concat([Ridge_metrics, pd.DataFrame([metrics])], ignore_index=True)\n","    \n","    combined = pd.concat([y_test, pd.Series(preds, index=test.index)], axis=1)\n","    combined.columns = ['Actual', 'Predictions']\n","    print(f'Best Params for Station {i} : {grid_search.best_params_}')\n","\n","    count = i % 6\n","    ax[count].plot(combined.index, combined['Actual'], label='Actual')\n","    ax[count].plot(combined.index, combined['Predictions'], label='Predicted')\n","    ax[count].set_title(f'Station {station}\\n')\n","    ax[count].tick_params(axis='x', rotation=45)\n","    \n","    if (count == 5) or (i == (len(stations) - 1)):\n","        plt.legend(loc='upper left', bbox_to_anchor=(1.0, 1.05))\n","        plt.tight_layout()\n","        plt.show()\n","        \n","        if i != (len(stations) - 1):\n","            fig, ax = plt.subplots(1, 6, figsize=(22, 3))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["Ridge_metrics"]},{"cell_type":"markdown","metadata":{},"source":["### 6. ElasticNet Regression"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["ElasticNet_metrics = pd.DataFrame(columns=['Station', 'MAE', 'MSE', 'RMSE', 'Accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["params = {'alpha': [0.001,0.003,0.01,0.03,0.1,0.3,1,3,10],\n","          'l1_ratio': np.arange(0.30,1.00,0.10),\n","           'tol' : [0.0001,0.001]\n","         }"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["stations = sorted(weather_india_final['STATION'].unique())\n","fig, ax = plt.subplots(1, 6, figsize=(22, 3))\n","fig.suptitle('ElasticNet Regression')\n","for i, station in enumerate(stations):\n","    df = weather_india_final[weather_india_final['STATION'] == station].copy() \n","    df.drop(['STATION'], axis=1, inplace=True)\n","    \n","    train = df.loc[:'2020-06-30']\n","    X_train = train.drop('Target', axis=1)\n","    y_train = train['Target']\n","    \n","\n","    test = df.loc['2020-07-01':]\n","    X_test = test.drop(['Target'], axis=1)\n","    y_test = test['Target']\n","    \n","    sc = StandardScaler()\n","    X_train_scaled = sc.fit_transform(X_train)\n","    X_test_scaled = sc.transform(X_test)\n","    \n","    grid_search = GridSearchCV(estimator=ElasticNet(), param_grid=params, scoring='neg_mean_squared_error', cv=5)\n","    grid_search.fit(X_train_scaled, y_train)\n","    \n","    preds = grid_search.predict(X_test_scaled)\n","\n","    metrics = {'Station': i, 'MAE': mean_absolute_error(y_test, preds), 'MSE': mean_squared_error(y_test, preds),\n","    'RMSE': np.sqrt(mean_squared_error(y_test, preds)), 'Accuracy': str(round(100 - (np.mean(np.abs(y_test - preds) / y_test) * 100), 2)) + '%'}\n","\n","    ElasticNet_metrics = pd.concat([ElasticNet_metrics, pd.DataFrame([metrics])], ignore_index=True)\n","    \n","    combined = pd.concat([y_test, pd.Series(preds, index=test.index)], axis=1)\n","    combined.columns = ['Actual', 'Predictions']\n","\n","    print(f'Best Params for Station {i} : {grid_search.best_params_}')\n","    \n","    count = i % 6\n","    ax[count].plot(combined.index, combined['Actual'], label='Actual')\n","    ax[count].plot(combined.index, combined['Predictions'], label='Predicted')\n","    ax[count].set_title(f'Station {station}')\n","    ax[count].tick_params(axis='x', rotation=45)\n","    \n","    if (count == 5) or (i == (len(stations) - 1)):\n","        plt.legend(loc='upper left', bbox_to_anchor=(1.0, 1.05))\n","        plt.tight_layout()\n","        plt.show()\n","        \n","        if i != (len(stations) - 1):\n","            fig, ax = plt.subplots(1, 6, figsize=(22, 3))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["ElasticNet_metrics"]},{"cell_type":"markdown","metadata":{},"source":["### 7. SVR(Support Vector Regressor)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["svr_metrics = pd.DataFrame(columns=['Station', 'MAE', 'MSE', 'RMSE', 'Accuracy'])"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["params_svr = { \n","                'kernel': ['linear', 'rbf','poly'], \n","                'C':[1.5, 10],\n","                'gamma': [1e-7, 1e-4],\n","                'epsilon':[0.1,0.2,0.5,0.3]\n","             }"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["stations = sorted(weather_india_final['STATION'].unique())\n","fig, ax = plt.subplots(1, 6, figsize=(22, 3))\n","fig.suptitle('Ridge Regression')\n","for i, station in enumerate(stations):\n","    df = weather_india_final[weather_india_final['STATION'] == station].copy() \n","    df.drop(['STATION'], axis=1, inplace=True)\n","    \n","    train = df.loc[:'2020-06-30']\n","    X_train = train.drop('Target', axis=1)\n","    y_train = train['Target']\n","    \n","\n","    test = df.loc['2020-07-01':]\n","    X_test = test.drop(['Target'], axis=1)\n","    y_test = test['Target']\n","    \n","    sc = StandardScaler()\n","    X_train_scaled = sc.fit_transform(X_train)\n","    X_test_scaled = sc.transform(X_test)\n","    \n","    svr = GridSearchCV(estimator=SVR(), param_grid=params_svr, scoring='neg_mean_squared_error', cv=2)\n","    svr.fit(X_train_scaled, y_train)\n","    \n","    preds = svr.predict(X_test_scaled)\n","\n","    metrics = {'Station': i, 'MAE': mean_absolute_error(y_test, preds), 'MSE': mean_squared_error(y_test, preds),\n","    'RMSE': np.sqrt(mean_squared_error(y_test, preds)), 'Accuracy': str(round(100 - (np.mean(np.abs(y_test - preds) / y_test) * 100), 2)) + '%'}\n","\n","    svr_metrics = pd.concat([svr_metrics, pd.DataFrame([metrics])], ignore_index=True)\n","    \n","    combined = pd.concat([y_test, pd.Series(preds, index=test.index)], axis=1)\n","    combined.columns = ['Actual', 'Predictions']\n","    \n","    print(f'Best Params for Station {i} : {grid_search.best_params_}')\n","    count = i % 6\n","    ax[count].plot(combined.index, combined['Actual'], label='Actual')\n","    ax[count].plot(combined.index, combined['Predictions'], label='Predicted')\n","    ax[count].set_title(f'Station {station}\\n')\n","    ax[count].tick_params(axis='x', rotation=45)\n","    \n","    if (count == 5) or (i == (len(stations) - 1)):\n","        plt.legend(loc='upper left', bbox_to_anchor=(1.0, 1.05))\n","        plt.tight_layout()\n","        plt.show()\n","        \n","        if i != (len(stations) - 1):\n","            fig, ax = plt.subplots(1, 6, figsize=(22, 3))"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["svr_metrics"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["Linear_plot = pd.DataFrame({    \n","    \"MAE\" : Linear_metrics['MAE'],\n","    \"MSE\" : Linear_metrics['MSE'],\n","    \"RMSE\" : Linear_metrics['RMSE']\n","})\n","\n","Poly_plot = pd.DataFrame({    \n","    \"MAE\" : Poly_metrics['MAE'],\n","    \"MSE\" : Poly_metrics['MSE'],\n","    \"RMSE\" : Poly_metrics['RMSE']\n","})\n","\n","SGD_plot = pd.DataFrame({    \n","    \"MAE\" : sgd_metrics['MAE'],\n","    \"MSE\" : sgd_metrics['MSE'],\n","    \"RMSE\" : sgd_metrics['RMSE']\n","})\n","\n","Lasso_plot = pd.DataFrame({\n","    \"MAE\": lasso_metrics['MAE'],  \n","    \"MSE\": lasso_metrics['MSE'], \n","    \"RMSE\": lasso_metrics['RMSE']\n","})\n","\n","Ridge_plot = pd.DataFrame({\n","    \"MAE\": Ridge_metrics['MAE'], \n","    \"MSE\": Ridge_metrics['MSE'], \n","    \"RMSE\": Ridge_metrics['RMSE']\n","})\n","\n","ElasticNet_plot = pd.DataFrame({\n","    \"MAE\": ElasticNet_metrics['MAE'], \n","    \"MSE\": ElasticNet_metrics['MSE'], \n","    \"RMSE\": ElasticNet_metrics['RMSE']\n","})\n","\n","Svr_plot = pd.DataFrame({\n","    \"MAE\": svr_metrics['MAE'],  \n","    \"MSE\": svr_metrics['MSE'],  \n","    \"RMSE\": svr_metrics['RMSE']\n","})\n","\n","stations = sorted(weather_india_final['STATION'].unique())\n","\n","\n","num_rows = len(stations)  \n","num_cols = 3   \n","\n","fig_width = 16\n","fig_height = 4 * num_rows\n","\n","fig, axes = plt.subplots(num_rows, num_cols, figsize=(fig_width, fig_height))\n","plt.subplots_adjust(top=0.9)\n","\n","fig.suptitle('Model Comparison',y=1.0)  \n","for i, station in enumerate(stations):\n","    \n","    mae_A = Linear_plot[\"MAE\"].iloc[i]\n","    mse_A = Linear_plot[\"MSE\"].iloc[i]\n","    rmse_A = Linear_plot[\"RMSE\"].iloc[i]\n","    mae_B = Poly_plot[\"MAE\"].iloc[i]\n","    mse_B = Poly_plot[\"MSE\"].iloc[i]\n","    rmse_B = Poly_plot[\"RMSE\"].iloc[i]\n","    mae_C = SGD_plot[\"MAE\"].iloc[i]\n","    mse_C = SGD_plot[\"MSE\"].iloc[i]\n","    rmse_C = SGD_plot[\"RMSE\"].iloc[i]\n","    mae_D = Lasso_plot[\"MAE\"].iloc[i]\n","    mse_D = Lasso_plot[\"MSE\"].iloc[i]\n","    rmse_D = Lasso_plot[\"RMSE\"].iloc[i]\n","    mae_E = Ridge_plot[\"MAE\"].iloc[i]\n","    mse_E = Ridge_plot[\"MSE\"].iloc[i]\n","    rmse_E = Ridge_plot[\"RMSE\"].iloc[i]  \n","    mae_F = ElasticNet_plot[\"MAE\"].iloc[i]\n","    mse_F = ElasticNet_plot[\"MSE\"].iloc[i]\n","    rmse_F = ElasticNet_plot[\"RMSE\"].iloc[i]\n","    mae_G = Svr_plot[\"MAE\"].iloc[i]\n","    mse_G = Svr_plot[\"MSE\"].iloc[i]\n","    rmse_G = Svr_plot[\"RMSE\"].iloc[i]\n","    \n","    \n","    row = i  \n","    col_mae = 0  \n","    col_mse = 1  \n","    col_rmse = 2\n","    \n","    models = ['Linear', 'Polynomial', 'SGD', 'Lasso', 'Ridge', 'Elastic Net', 'SVR']\n","    mae_values = [mae_A, mae_B, mae_C, mae_D, mae_E, mae_F, mae_G]\n","    bar_positions = range(len(models))\n","    axes[row, col_mae].bar(models, mae_values, color=['b', 'r', 'g', 'c', 'm', 'y', 'k'], alpha=0.7)\n","    axes[row, col_mae].set_title(f'Station {station} - MAE')\n","    \n","    max_mae = max(mae_values)\n","    for x, y in zip(bar_positions, mae_values):\n","        axes[row, col_mae].text(x, max_mae / 2, f'{y:.2f}', ha='center', va='center')\n","    \n","    mse_values = [mse_A, mse_B, mse_C, mse_D, mse_E, mse_F, mse_G]\n","    axes[row, col_mse].bar(models, mse_values, color=['b', 'r', 'g', 'c', 'm', 'y', 'k'], alpha=0.7)\n","    axes[row, col_mse].set_title(f'Station {station} - MSE')\n","    \n","    max_mse = max(mse_values)\n","    for x, y in zip(bar_positions, mse_values):\n","        axes[row, col_mse].text(x, max_mse / 2, f'{y:.2f}', ha='center', va='center')\n","        \n","    rmse_values = [rmse_A, rmse_B, rmse_C, rmse_D, rmse_E, rmse_F, rmse_G]\n","    axes[row, col_rmse].bar(models, rmse_values, color=['b', 'r', 'g', 'c', 'm', 'y', 'k'], alpha=0.7)\n","    axes[row, col_rmse].set_title(f'Station {station} - RMSE')\n","    \n","    max_rmse = max(rmse_values)\n","    for x, y in zip(bar_positions, rmse_values):\n","        axes[row, col_rmse].text(x, max_rmse / 2, f'{y:.2f}', ha='center', va='center')\n","\n","plt.tight_layout()\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.8"}},"nbformat":4,"nbformat_minor":4}
